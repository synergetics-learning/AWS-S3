{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python SDK for accessing S3\n",
    "<ol>\n",
    "    <li>Install Python SDK boto3</li>\n",
    "    <li>Necessary imports</li>\n",
    "    <li>Create a client to work using low level functions.</li>\n",
    "    <li>Create a resource to work using high level objects.</li>\n",
    "    <li>List buckets.</li>\n",
    "    <li>Creating buckets.</li>\n",
    "    <li>Reading file.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Python SDK boto3 using following command\n",
    "pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Create a client\n",
    " * If you want to work with single S3 files, you can choose to work with the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the low level functional client\n",
    "client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id = 'AKIAWGBN43TA2L3YKKEM',\n",
    "    aws_secret_access_key = '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',\n",
    "    region_name = 'ap-south-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a resource\n",
    " * However, if you need to work with multiple S3 buckets and need to iterate over those, then using resources would be ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the high level object oriented interface\n",
    "resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id = 'AKIAWGBN43TA2L3YKKEM',\n",
    "    aws_secret_access_key = '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',\n",
    "    region_name = 'ap-south-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. List buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing bucket names...\n",
      "Bucket Name: chandradata\n"
     ]
    }
   ],
   "source": [
    "# Fetch the list of existing buckets\n",
    "clientResponse = client.list_buckets()\n",
    "    \n",
    "# Print the bucket names one by one\n",
    "print('Printing bucket names...')\n",
    "for bucket in clientResponse['Buckets']:\n",
    "    print(f'Bucket Name: {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'C573A9N5HTNJN1F1',\n",
       "  'HostId': '0D2hnPIEhuNVwa4f1HJfEwkbDW20MUfjzCYGk4hJ1QRClstVABgx3S2aCdyxKTY/UEObrJh9E2s=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '0D2hnPIEhuNVwa4f1HJfEwkbDW20MUfjzCYGk4hJ1QRClstVABgx3S2aCdyxKTY/UEObrJh9E2s=',\n",
       "   'x-amz-request-id': 'C573A9N5HTNJN1F1',\n",
       "   'date': 'Tue, 31 Jan 2023 15:24:50 GMT',\n",
       "   'location': 'http://chandradatacopy.s3.amazonaws.com/',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': 'http://chandradatacopy.s3.amazonaws.com/'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a bucket using Python code\n",
    "# Creating a bucket in AWS S3\n",
    "location = {'LocationConstraint': 'ap-south-1'}\n",
    "client.create_bucket(\n",
    "    Bucket='chandradatacopy',\n",
    "    CreateBucketConfiguration=location\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Read CSV file to create a Panda's data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the data frame...\n",
      "      Id  Loan_ID  Gender  Marital  Dependents  Education  SelfEmplo  \\\n",
      "0      0  LP00001       1        1           1          1          0   \n",
      "1      1  LP00002       1        1           0          1          1   \n",
      "2      2  LP00003       1        1           0          0          0   \n",
      "3      3  LP00004       1        0           0          1          0   \n",
      "4      4  LP00005       1        1           2          1          1   \n",
      "..   ...      ...     ...      ...         ...        ...        ...   \n",
      "608  608  LP00609       0        0           0          1          0   \n",
      "609  609  LP00610       1        1           3          1          0   \n",
      "610  610  LP00611       1        1           1          1          0   \n",
      "611  611  LP00612       1        1           2          1          0   \n",
      "612  612  LP00613       0        0           0          1          1   \n",
      "\n",
      "     ApplIncome  CoApplIncome  Loan Amt   Term  CreditHistory  PropArea  \\\n",
      "0          4583        1508.0       128  360.0            1.0         0   \n",
      "1          3000           0.0        66  360.0            1.0         1   \n",
      "2          2583        2358.0       120  360.0            1.0         1   \n",
      "3          6000           0.0       141  360.0            1.0         1   \n",
      "4          5417        4196.0       267  360.0            1.0         1   \n",
      "..          ...           ...       ...    ...            ...       ...   \n",
      "608        2900           0.0        71  360.0            1.0         0   \n",
      "609        4106           0.0        40  180.0            1.0         0   \n",
      "610        8072         240.0       253  360.0            1.0         1   \n",
      "611        7583           0.0       187  360.0            1.0         1   \n",
      "612        4583           0.0       133  360.0            0.0         2   \n",
      "\n",
      "     LoanStatus  \n",
      "0             0  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "..          ...  \n",
      "608           1  \n",
      "609           1  \n",
      "610           1  \n",
      "611           1  \n",
      "612           0  \n",
      "\n",
      "[613 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the S3 object\n",
    "obj = client.get_object(\n",
    "    Bucket = 'chandradata',\n",
    "    Key = 'LoanData_Raw.csv'\n",
    ")\n",
    "    \n",
    "# Read data from the S3 object\n",
    "data = pandas.read_csv(obj['Body'])\n",
    "    \n",
    "# Print the data frame\n",
    "print('Printing the data frame...')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7b34aaeb780b7f6a9b0f73fc0214dc6537b2a0fecf5a578c44baf20c14848af"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
